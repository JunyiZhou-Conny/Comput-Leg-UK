{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curl_cffi import requests\n",
    "from curl_cffi.requests.errors import RequestsError\n",
    "from requests.exceptions import HTTPError\n",
    "from requests.exceptions import RequestException\n",
    "from requests.exceptions import Timeout\n",
    "from requests.exceptions import TooManyRedirects\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hansard.parliament.uk/html/commons/2014-12-04/CommonsChamber\n"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "# Base URL for the Hansard site\n",
    "base_url = 'https://hansard.parliament.uk/html/commons'\n",
    "\n",
    "# Function to build the full URL for a given date\n",
    "def build_url_for_date(date):\n",
    "    return f\"{base_url}/{date}/CommonsChamber\"\n",
    "\n",
    "url  = build_url_for_date('2014-12-04')\n",
    "print(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hansard.parliament.uk/debates/GetDebateAsText/b6632d8a-5617-4ef7-9fb9-0e1dc1da22d4\n"
     ]
    }
   ],
   "source": [
    "def text_download(url):\n",
    "    base_url = 'https://hansard.parliament.uk'\n",
    "    try:\n",
    "        response = session.get(url, impersonate='chrome110')\n",
    "\n",
    "    \n",
    "    except RequestsError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "        return []\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred: {conn_err}\")\n",
    "        return []\n",
    "    except requests.exceptions.Timeout as timeout_err:\n",
    "        print(f\"Timeout error occurred: {timeout_err}\")\n",
    "        return []\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"An error occurred during the request: {req_err}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text_link = soup.find('a', class_='icon-link', href=lambda h: h and 'GetDebateAsText' in h)\n",
    "    if text_link is None:# If there is no text link, return an empty list, and print a message\n",
    "        return []\n",
    "    full_url = base_url + text_link['href']\n",
    "    return full_url\n",
    "\n",
    "print(text_download(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_df_to_s3(df, bucket, object_name):\n",
    "    \"\"\"\n",
    "    Upload a DataFrame to an S3 bucket as CSV.\n",
    "\n",
    "    :param df: DataFrame to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name\n",
    "    :return: True if the DataFrame was uploaded, else False\n",
    "    \"\"\"\n",
    "    # Create a buffer\n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    # Move to the start of the buffer\n",
    "    csv_buffer.seek(0)\n",
    "\n",
    "    #When setting up credentials locally, use the following code\n",
    "    session = boto3.Session()\n",
    "    s3_client = session.client('s3')\n",
    "    # # # When using IAM roles, boto3 retrieves credentials from the instance metadata\n",
    "    # s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "    try:\n",
    "        s3_client.put_object(Bucket=bucket, Key=object_name, Body=csv_buffer.getvalue())\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No texts found for download 2000-01-01\n",
      "No texts found for download 2000-01-02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "\n",
    "def upload_text_to_s3(text, bucket, object_name):\n",
    "    \"\"\"\n",
    "    Upload a text to an S3 bucket.\n",
    "\n",
    "    :param text: Text to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name\n",
    "    :return: True if the text was uploaded, else False\n",
    "    \"\"\"\n",
    "    # Create a buffer\n",
    "    text_buffer = io.StringIO()\n",
    "    text_buffer.write(text)\n",
    "\n",
    "    # Move to the start of the buffer\n",
    "    text_buffer.seek(0)\n",
    "\n",
    "    # When setting up credentials locally, use the following code\n",
    "    session = boto3.Session()\n",
    "    s3_client = session.client('s3')\n",
    "\n",
    "    try:\n",
    "        s3_client.put_object(Bucket=bucket, Key=object_name, Body=text_buffer.getvalue())\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "#Generate a list of dates\n",
    "import datetime\n",
    "start_date = datetime.date(2000, 1, 1)\n",
    "end_date = datetime.date(2000, 1, 2)\n",
    "delta = datetime.timedelta(days=1)\n",
    "dates = []\n",
    "while start_date <= end_date:\n",
    "    dates.append(start_date)\n",
    "    start_date += delta\n",
    "\n",
    "\n",
    "\n",
    "Hansard_Failed = []\n",
    "Hansard_NoText = []\n",
    "bucket_name = 'myukdata'\n",
    "folder_path = 'Hansard_Common_Chambers'\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for date in dates:\n",
    "    # Build the URL for the date\n",
    "    hansard_url = build_url_for_date(date)\n",
    "\n",
    "    # Get the text link for the date, this is the download text button on the top left of the page\n",
    "    text_link = text_download(hansard_url)\n",
    "\n",
    "    if text_link == []:\n",
    "        Hansard_NoText.append(date.strftime('%Y-%m-%d'))\n",
    "        print(f\"No texts found for download {date}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Text link found:{text_link} for {date}\")\n",
    "        response_text = requests.get(text_link, impersonate='chrome110')\n",
    "        if response_text.status_code == 200:\n",
    "            print(f\"Text downloaded for {date}\")\n",
    "            # Upload the DataFrame to S3\n",
    "            upload_text_to_s3(response_text.text, bucket_name, f\"{folder_path}/Hansard_{date.strftime('%Y-%m-%d')}.txt\")\n",
    "        else:\n",
    "            print(f\"Text download failed for {date}\")\n",
    "            Hansard_Failed.append(date.strftime('%Y-%m-%d'))\n",
    "\n",
    "Hansard_Failed = pd.DataFrame(Hansard_Failed)\n",
    "Hansard_NoText = pd.DataFrame(Hansard_NoText)\n",
    "if Hansard_Failed.empty == False:\n",
    "    Hansard_Failed.columns = ['Date']\n",
    "if Hansard_NoText.empty == False:\n",
    "    Hansard_NoText.columns = ['Date']\n",
    "upload_df_to_s3(Hansard_Failed, bucket_name, f\"{folder_path}/Hansard_FailedS3.csv\")\n",
    "upload_df_to_s3(Hansard_NoText, bucket_name, f\"{folder_path}/Hansard_NoSitting.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
